{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9e1ae43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:05:13.960681Z",
     "iopub.status.busy": "2024-09-09T12:05:13.960030Z",
     "iopub.status.idle": "2024-09-09T12:05:16.073713Z",
     "shell.execute_reply": "2024-09-09T12:05:16.073457Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import shutil\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79fce9a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:05:16.075508Z",
     "iopub.status.busy": "2024-09-09T12:05:16.075301Z",
     "iopub.status.idle": "2024-09-09T12:05:16.079076Z",
     "shell.execute_reply": "2024-09-09T12:05:16.078654Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100\n",
      "Destination: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100\n"
     ]
    }
   ],
   "source": [
    "# Get source and destination from environment variables\n",
    "src = os.getenv('SRC_PATH')\n",
    "dst = os.getenv('DST_PATH')\n",
    "\n",
    "if not src or not dst:\n",
    "    print(\"Source or destination path not provided.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Ensure that the source directory exists\n",
    "if not os.path.exists(src):\n",
    "    print(f\"Source path does not exist: {src}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# Ensure that the destination directory exists or create it\n",
    "if not os.path.exists(dst):\n",
    "    os.makedirs(dst, exist_ok=True)\n",
    "\n",
    "print(f\"Source: {src}\")\n",
    "print(f\"Destination: {dst}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62011b25-f41f-4fcc-af33-b786864c6dba",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:05:16.080942Z",
     "iopub.status.busy": "2024-09-09T12:05:16.080805Z",
     "iopub.status.idle": "2024-09-09T12:05:16.087482Z",
     "shell.execute_reply": "2024-09-09T12:05:16.087207Z"
    }
   },
   "outputs": [],
   "source": [
    "# Paths to datasets with DePlot tables\n",
    "figureqa_pattern = os.path.join(src, \"FigureQA/**/*.csv\")\n",
    "plotqa_pattern = os.path.join(src, \"PlotQA/**/*.csv\")\n",
    "\n",
    "# Function to filter out ChartQA CSVs\n",
    "def valid_chartqa_file(file_path):\n",
    "    # Get file name without extension\n",
    "    base_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "    \n",
    "    # Ensure it follows the naming pattern chartQA_{name}-{split}\n",
    "    if base_name.startswith(\"chartQA_\") and \"-\" in base_name:\n",
    "        name_part = base_name.split(\"chartQA_\")[1].split(\"-\")[0]\n",
    "        # Return True if the name part has fewer than 9 characters\n",
    "        return len(name_part) < 9\n",
    "    return False\n",
    "\n",
    "chartqa_pattern = os.path.join(src, \"ChartQA/**/*.csv\")\n",
    "\n",
    "# Get all DePlot CSV files \n",
    "figureqa_files = glob.glob(figureqa_pattern, recursive=True)\n",
    "plotqa_files = glob.glob(plotqa_pattern, recursive=True)\n",
    "chartqa_files = [file for file in glob.glob(chartqa_pattern, recursive=True) if valid_chartqa_file(file)]\n",
    "\n",
    "# Combine all files\n",
    "all_files = figureqa_files + plotqa_files + chartqa_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f1b5847",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:05:16.089130Z",
     "iopub.status.busy": "2024-09-09T12:05:16.089012Z",
     "iopub.status.idle": "2024-09-09T12:05:16.093332Z",
     "shell.execute_reply": "2024-09-09T12:05:16.093032Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Convert data string to a DataFrame and a title '''\n",
    "def string_to_dataframe_and_title(data_string, filepath):\n",
    "    # Split the data into rows\n",
    "    rows = data_string.strip().split(\"<0x0A>\")\n",
    "    \n",
    "    title = None\n",
    "    header = None\n",
    "\n",
    "    # Check if the first row is a title and extract it\n",
    "    if \"TITLE |\" in rows[0]:\n",
    "        potential_title = rows[0].split(\" | \", 1)[1]  # Split and take second part as the potential title\n",
    "        if potential_title.strip().lower() not in ['', 'title']: # Handle cases with placeholder titles\n",
    "            title = potential_title  # Only set title if its meaningful\n",
    "        rows.pop(0)  # Remove the title row from processing\n",
    "\n",
    "    # The next row should be the header\n",
    "    if rows:\n",
    "        header = [h.strip() for h in rows.pop(0).split(\"|\") if h.strip()]\n",
    "        # rows.pop(0).split(\" | \")\n",
    "    else:\n",
    "        raise ValueError(\"No header row found after the title row.\")\n",
    "\n",
    "    # Check if there are any data rows left after removing title and header\n",
    "    if not rows:\n",
    "        raise ValueError(\"No data rows found after the header row.\")\n",
    "\n",
    "    # Split remaining rows based on number of headers\n",
    "    records = []\n",
    "    for row in rows:\n",
    "        record = [r.strip() for r in row.strip().split(\"|\") if r.strip()]\n",
    "        if len(record) != len(header):\n",
    "            print(f\"File: {filepath}: Row has {len(record)} columns, expected {len(header)} - row data: {record}\")\n",
    "            return None, title  # to keep original CSV instead\n",
    "        records.append(record)\n",
    "\n",
    "    # Create df and convert data to numeric where possible\n",
    "    df = pd.DataFrame(records, columns=header).apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    return df, title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc21f65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:05:16.094948Z",
     "iopub.status.busy": "2024-09-09T12:05:16.094856Z",
     "iopub.status.idle": "2024-09-09T12:05:16.097106Z",
     "shell.execute_reply": "2024-09-09T12:05:16.096832Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Save the title to a separate txt file '''\n",
    "def save_title_to_file(title, filepath):\n",
    "    if title:\n",
    "        title_filepath = f\"{filepath.rsplit('.', 1)[0]}.txt\" # same name with 'txt' extension\n",
    "        with open(title_filepath, 'w') as f:\n",
    "            f.write(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ed37a94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:05:16.098601Z",
     "iopub.status.busy": "2024-09-09T12:05:16.098511Z",
     "iopub.status.idle": "2024-09-09T12:05:16.101937Z",
     "shell.execute_reply": "2024-09-09T12:05:16.101657Z"
    }
   },
   "outputs": [],
   "source": [
    "''' Handle reformatting of non properly formatted CSVs '''\n",
    "def process_non_formatted_csv(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        data_string = file.read()\n",
    "\n",
    "    # Split rows based on <0x0A> delimiter\n",
    "    rows = data_string.split('<0x0A>')\n",
    "\n",
    "    title = None\n",
    "\n",
    "    # Check if first row is a title and extract it\n",
    "    if \"TITLE |\" in rows[0]:\n",
    "        potential_title = rows[0].split(\" | \", 1)[1]  # Split and take second part as potential title\n",
    "        if potential_title.strip().lower() not in ['', 'title']:  # Handle cases with placeholder titles\n",
    "            title = potential_title  # Only set title if its meaningful\n",
    "        rows.pop(0)  # Remove the title row from processing\n",
    "\n",
    "    # Split each row by | delimiter to get columns\n",
    "    split_rows = [row.strip().split('|') for row in rows]\n",
    "\n",
    "    # Find the maximum number of columns across all rows\n",
    "    max_columns = max(len(row) for row in split_rows)\n",
    "\n",
    "    # Pad rows with fewer columns with blank space\n",
    "    formatted_rows = [row + [np.nan] * (max_columns-len(row)) for row in split_rows]\n",
    "\n",
    "    df = pd.DataFrame(formatted_rows)\n",
    "\n",
    "    # Save corrected df back to same file \n",
    "    df.to_csv(file_path, index=False, header=False)\n",
    "\n",
    "    # Save title to a separate file if it exists\n",
    "    if title:\n",
    "        save_title_to_file(title, file_path)\n",
    "\n",
    "    print(f\"Reformatted table saved to: {file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62120ca5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:05:16.103444Z",
     "iopub.status.busy": "2024-09-09T12:05:16.103361Z",
     "iopub.status.idle": "2024-09-09T12:05:16.106828Z",
     "shell.execute_reply": "2024-09-09T12:05:16.106590Z"
    }
   },
   "outputs": [],
   "source": [
    "# Main Processing Logic\n",
    "def process_csv_files(src, dst):\n",
    "    if not os.path.exists(dst):\n",
    "        os.makedirs(dst)\n",
    "    \n",
    "    # data_pattern = os.path.join(src, '**', '*-dp.csv')\n",
    "\n",
    "    csvs_not_converted_properly = []\n",
    "\n",
    "    for filepath in all_files:\n",
    "    # glob.glob(data_pattern, recursive=True):\n",
    "        with open(filepath, 'r') as file:\n",
    "            data_string = file.read()\n",
    "\n",
    "        try:\n",
    "            result = string_to_dataframe_and_title(data_string, filepath)\n",
    "            if result is None:\n",
    "                print(f\"Skipping conversion for {filepath} because it removes data.\")\n",
    "                continue\n",
    "\n",
    "            df, title = result\n",
    "\n",
    "            if df is not None:\n",
    "                # Save the DataFrame (overwrite original file)\n",
    "                df.to_csv(filepath, index=False)\n",
    "\n",
    "                # Save the title to a separate file\n",
    "                save_title_to_file(title, filepath)\n",
    "                print(f\"Preprocessing successful for {filepath}\")\n",
    "            else:\n",
    "                csvs_not_converted_properly.append(filepath)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing {filepath}: {e}\")\n",
    "\n",
    "    if csvs_not_converted_properly:\n",
    "        print(f\"CSV files not converted properly: {csvs_not_converted_properly}\")\n",
    "        print(f\"Number of CSVs not converted properly: {len(csvs_not_converted_properly)}\")\n",
    "\n",
    "        for file_path in csvs_not_converted_properly:\n",
    "            print(f\"Fixing formatting for: {file_path}\")\n",
    "            process_non_formatted_csv(file_path)\n",
    "    else:\n",
    "        print(\"No CSV files need reformatting.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06247c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-09T12:05:16.109012Z",
     "iopub.status.busy": "2024-09-09T12:05:16.108905Z",
     "iopub.status.idle": "2024-09-09T12:05:16.152519Z",
     "shell.execute_reply": "2024-09-09T12:05:16.152299Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_43249-train.csv\n",
      "File: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_96216-train.csv: Row has 3 columns, expected 5 - row data: ['2026', '9.46', '80.50']\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_51171-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_66119-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_34683-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_80487-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_20856-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_55737-train.csv\n",
      "File: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_63032-train.csv: Row has 1 columns, expected 8 - row data: ['hot_pink']\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_42962-train.csv\n",
      "File: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_23322-train.csv: Row has 5 columns, expected 4 - row data: ['Red', '4', '1', '3', '1']\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_96310-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_37961-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_63892-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_99722-train.csv\n",
      "File: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_82199-train.csv: Row has 3 columns, expected 8 - row data: ['Seafoam', '16.1', '10.3']\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_90769-train.csv\n",
      "File: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_43461-train.csv: Row has 4 columns, expected 3 - row data: ['Medium Seafoam', '13.7', '13.1', '13.7']\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_19952-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_56247-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/test/tables/plotQA_1467-test.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/test/tables/plotQA_23071-test.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/test/tables/plotQA_1178-test.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/test/tables/plotQA_21579-test.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/test/tables/plotQA_29479-test.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_126784-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_92173-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_139568-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_26296-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_13192-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_148613-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_41979-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_40066-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_145467-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_49754-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_29819-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_41193-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_28366-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_154195-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_98527-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_156791-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_127221-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_8347-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_99631-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_101809-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_37698-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_133988-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_36612-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_123057-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_131728-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_58019-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_103743-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_47197-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_86304-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/train/tables/plotQA_140860-train.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/val/tables/plotQA_20477-val.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/val/tables/plotQA_4212-val.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/val/tables/plotQA_27994-val.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/val/tables/plotQA_20471-val.csv\n",
      "Preprocessing successful for /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/PlotQA/val/tables/plotQA_19779-val.csv\n",
      "CSV files not converted properly: ['/Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_96216-train.csv', '/Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_63032-train.csv', '/Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_23322-train.csv', '/Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_82199-train.csv', '/Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_43461-train.csv']\n",
      "Number of CSVs not converted properly: 5\n",
      "Fixing formatting for: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_96216-train.csv\n",
      "Reformatted table saved to: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_96216-train.csv\n",
      "Fixing formatting for: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_63032-train.csv\n",
      "Reformatted table saved to: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_63032-train.csv\n",
      "Fixing formatting for: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_23322-train.csv\n",
      "Reformatted table saved to: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_23322-train.csv\n",
      "Fixing formatting for: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_82199-train.csv\n",
      "Reformatted table saved to: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_82199-train.csv\n",
      "Fixing formatting for: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_43461-train.csv\n",
      "Reformatted table saved to: /Users/evie/Documents/GitHub/ChartFact/seed_datasets_100/3_translated_data_100/FigureQA/train/tables/figureQA_43461-train.csv\n"
     ]
    }
   ],
   "source": [
    "process_csv_files(src, dst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
